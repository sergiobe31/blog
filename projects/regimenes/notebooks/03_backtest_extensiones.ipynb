{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtest y Extensiones del Modelo\n",
    "\n",
    "**Notebook 3 de 3** | Aplicación Práctica y Simulación\n",
    "\n",
    "En este notebook:\n",
    "1. Definimos una estrategia simple basada en regímenes\n",
    "2. Implementamos backtest con walk-forward validation\n",
    "3. Comparamos contra Buy & Hold\n",
    "4. Generamos series sintéticas con la matriz de transición\n",
    "5. Discutimos extensiones futuras\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup y Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para Google Colab: descomentar y ejecutar\n",
    "# !pip install -q yfinance statsmodels networkx\n",
    "# !git clone https://github.com/tu-usuario/blog_regimenes.git\n",
    "# %cd blog_regimenes/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from config import *\n",
    "from src.data import download_spy_data\n",
    "from src.features import compute_oliva_features\n",
    "from src.regimes import standardize_features, fit_kmeans, compute_transition_matrix\n",
    "from src.plotting import setup_plotting_style, save_figure, plot_equity_curves\n",
    "\n",
    "setup_plotting_style()\n",
    "\n",
    "SAVE_FIGURES = True\n",
    "FIGURES_PATH = \"../figures/post3/\"\n",
    "\n",
    "print(f\"Walk-forward: re-entrenar cada {WALK_FORWARD_RETRAIN_MONTHS} meses\")\n",
    "print(f\"Ventana de entrenamiento: {WALK_FORWARD_WINDOW_YEARS} años\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Descargar datos completos\n",
    "# df = download_spy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Definición de la Estrategia\n",
    "\n",
    "### Reglas simples:\n",
    "- **Régimen favorable (Bull Tranquilo, Bull Volátil):** 100% invertido en SPY\n",
    "- **Régimen desfavorable (Bear Volátil, Neutro):** 100% en cash (0% exposición)\n",
    "\n",
    "Esta es una estrategia simplificada para demostración. En producción se considerarían:\n",
    "- Costos de transacción\n",
    "- Slippage\n",
    "- Posiciones parciales\n",
    "- Reglas de confirmación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir qué regímenes son \"favorables\" para estar invertido\n",
    "# Esto se ajustará después de ver los centroides\n",
    "FAVORABLE_REGIMES = [0, 3]  # Bull Tranquilo, Bull Volátil\n",
    "UNFAVORABLE_REGIMES = [1, 2]  # Bear Volátil, Neutro\n",
    "\n",
    "def get_position(regime: int) -> float:\n",
    "    \"\"\"\n",
    "    Determina la posición basada en el régimen.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float : 1.0 si invertido, 0.0 si en cash\n",
    "    \"\"\"\n",
    "    return 1.0 if regime in FAVORABLE_REGIMES else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Walk-Forward Validation\n",
    "\n",
    "Para evitar look-ahead bias, implementamos walk-forward:\n",
    "1. Entrenar modelo con datos de los últimos N años\n",
    "2. Aplicar al siguiente periodo (M meses)\n",
    "3. Re-entrenar y repetir\n",
    "\n",
    "Parámetros:\n",
    "- **Ventana de entrenamiento:** 5 años\n",
    "- **Re-entrenamiento:** cada 12 meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_backtest(\n",
    "    df: pd.DataFrame,\n",
    "    train_window_years: int = WALK_FORWARD_WINDOW_YEARS,\n",
    "    retrain_months: int = WALK_FORWARD_RETRAIN_MONTHS,\n",
    "    start_date: str = \"2005-01-01\",  # Empezar después de tener suficiente historia\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ejecuta backtest con walk-forward validation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame con datos y columna 'returns'\n",
    "    train_window_years : int\n",
    "        Años de datos para entrenar\n",
    "    retrain_months : int\n",
    "        Frecuencia de re-entrenamiento en meses\n",
    "    start_date : str\n",
    "        Fecha de inicio del backtest\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame con columnas: returns, regime, position, strategy_returns\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Fechas de re-entrenamiento\n",
    "    start = pd.Timestamp(start_date)\n",
    "    end = df.index[-1]\n",
    "    \n",
    "    current_date = start\n",
    "    model = None\n",
    "    scaler = None\n",
    "    \n",
    "    while current_date < end:\n",
    "        # Definir ventana de entrenamiento\n",
    "        train_start = current_date - relativedelta(years=train_window_years)\n",
    "        train_end = current_date\n",
    "        \n",
    "        # Definir ventana de test (hasta próximo re-entrenamiento)\n",
    "        test_end = min(current_date + relativedelta(months=retrain_months), end)\n",
    "        \n",
    "        # Extraer datos\n",
    "        df_train = df.loc[train_start:train_end]\n",
    "        df_test = df.loc[train_end:test_end].iloc[1:]  # Excluir fecha de corte\n",
    "        \n",
    "        if len(df_train) < 252 or len(df_test) == 0:  # Mínimo 1 año de datos\n",
    "            current_date = test_end\n",
    "            continue\n",
    "        \n",
    "        # Calcular features y entrenar\n",
    "        features_train = compute_oliva_features(df_train)\n",
    "        features_scaled, scaler = standardize_features(features_train)\n",
    "        model, _ = fit_kmeans(features_scaled, k=K_REGIMES)\n",
    "        \n",
    "        # Aplicar a test\n",
    "        features_test = compute_oliva_features(df_test)\n",
    "        \n",
    "        # Alinear índices (features tienen menos filas por el rolling)\n",
    "        common_idx = features_test.index.intersection(df_test.index)\n",
    "        if len(common_idx) == 0:\n",
    "            current_date = test_end\n",
    "            continue\n",
    "            \n",
    "        features_test_scaled, _ = standardize_features(features_test.loc[common_idx], scaler=scaler)\n",
    "        labels_test = model.predict(features_test_scaled)\n",
    "        \n",
    "        # Calcular posiciones y retornos\n",
    "        for i, (idx, row) in enumerate(df_test.loc[common_idx].iterrows()):\n",
    "            regime = labels_test[i]\n",
    "            position = get_position(regime)\n",
    "            strategy_return = position * row['returns']\n",
    "            \n",
    "            results.append({\n",
    "                'date': idx,\n",
    "                'returns': row['returns'],\n",
    "                'regime': regime,\n",
    "                'position': position,\n",
    "                'strategy_returns': strategy_return,\n",
    "                'train_end': train_end,\n",
    "            })\n",
    "        \n",
    "        # Avanzar al siguiente periodo\n",
    "        current_date = test_end\n",
    "        print(f\"Periodo {train_end.strftime('%Y-%m')} -> {test_end.strftime('%Y-%m')}: {len(df_test.loc[common_idx])} días\")\n",
    "    \n",
    "    return pd.DataFrame(results).set_index('date')\n",
    "\n",
    "# TODO: Ejecutar backtest\n",
    "# backtest_results = walk_forward_backtest(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Cálculo de Equity Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_equity_curves(backtest_df: pd.DataFrame, initial_capital: float = 10000) -> tuple:\n",
    "    \"\"\"\n",
    "    Calcula curvas de equity para estrategia y buy & hold.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple : (equity_strategy, equity_benchmark)\n",
    "    \"\"\"\n",
    "    # Estrategia\n",
    "    cumulative_strategy = (1 + backtest_df['strategy_returns']).cumprod()\n",
    "    equity_strategy = initial_capital * cumulative_strategy\n",
    "    \n",
    "    # Buy & Hold\n",
    "    cumulative_bh = (1 + backtest_df['returns']).cumprod()\n",
    "    equity_benchmark = initial_capital * cumulative_bh\n",
    "    \n",
    "    return equity_strategy, equity_benchmark\n",
    "\n",
    "# TODO: Calcular equity curves\n",
    "# equity_strategy, equity_benchmark = compute_equity_curves(backtest_results)\n",
    "# \n",
    "# save_path = f\"{FIGURES_PATH}equity_curves.png\" if SAVE_FIGURES else None\n",
    "# plot_equity_curves(equity_strategy, equity_benchmark, save_path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Métricas de Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(returns: pd.Series, risk_free_rate: float = 0.02) -> dict:\n",
    "    \"\"\"\n",
    "    Calcula métricas de performance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : pd.Series\n",
    "        Serie de retornos diarios\n",
    "    risk_free_rate : float\n",
    "        Tasa libre de riesgo anual\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict : Diccionario con métricas\n",
    "    \"\"\"\n",
    "    # Retorno total\n",
    "    total_return = (1 + returns).prod() - 1\n",
    "    \n",
    "    # CAGR\n",
    "    n_years = len(returns) / 252\n",
    "    cagr = (1 + total_return) ** (1 / n_years) - 1 if n_years > 0 else 0\n",
    "    \n",
    "    # Volatilidad anualizada\n",
    "    volatility = returns.std() * np.sqrt(252)\n",
    "    \n",
    "    # Sharpe Ratio\n",
    "    excess_return = cagr - risk_free_rate\n",
    "    sharpe = excess_return / volatility if volatility > 0 else 0\n",
    "    \n",
    "    # Max Drawdown\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    rolling_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - rolling_max) / rolling_max\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # Calmar Ratio\n",
    "    calmar = cagr / abs(max_drawdown) if max_drawdown != 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'Total Return': f\"{total_return:.2%}\",\n",
    "        'CAGR': f\"{cagr:.2%}\",\n",
    "        'Volatility (Ann.)': f\"{volatility:.2%}\",\n",
    "        'Sharpe Ratio': f\"{sharpe:.2f}\",\n",
    "        'Max Drawdown': f\"{max_drawdown:.2%}\",\n",
    "        'Calmar Ratio': f\"{calmar:.2f}\",\n",
    "    }\n",
    "\n",
    "# TODO: Comparar métricas\n",
    "# metrics_strategy = compute_metrics(backtest_results['strategy_returns'])\n",
    "# metrics_benchmark = compute_metrics(backtest_results['returns'])\n",
    "# \n",
    "# comparison = pd.DataFrame({\n",
    "#     'Estrategia': metrics_strategy,\n",
    "#     'Buy & Hold': metrics_benchmark\n",
    "# })\n",
    "# comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Métricas adicionales\n",
    "# pct_time_invested = backtest_results['position'].mean()\n",
    "# n_trades = (backtest_results['position'].diff().abs() > 0).sum()\n",
    "# \n",
    "# print(f\"% Tiempo invertido: {pct_time_invested:.1%}\")\n",
    "# print(f\"Número de cambios de posición: {n_trades}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Análisis de Drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_drawdown_comparison(backtest_df: pd.DataFrame, save_path=None):\n",
    "    \"\"\"\n",
    "    Compara drawdown de estrategia vs benchmark.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    for label, returns_col, color in [\n",
    "        ('Estrategia', 'strategy_returns', '#2ecc71'),\n",
    "        ('Buy & Hold', 'returns', '#3498db')\n",
    "    ]:\n",
    "        cumulative = (1 + backtest_df[returns_col]).cumprod()\n",
    "        rolling_max = cumulative.expanding().max()\n",
    "        drawdown = (cumulative - rolling_max) / rolling_max\n",
    "        \n",
    "        ax.fill_between(drawdown.index, drawdown.values, 0, \n",
    "                       alpha=0.4, label=label, color=color)\n",
    "    \n",
    "    ax.set_xlabel('Fecha')\n",
    "    ax.set_ylabel('Drawdown')\n",
    "    ax.set_title('Drawdown: Estrategia vs Buy & Hold')\n",
    "    ax.legend()\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.0%}'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        save_figure(fig, save_path)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# TODO: Ejecutar\n",
    "# save_path = f\"{FIGURES_PATH}drawdown_comparacion.png\" if SAVE_FIGURES else None\n",
    "# plot_drawdown_comparison(backtest_results, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Limitación: Evaluación Retrospectiva\n",
    "\n",
    "Incluso con walk-forward, hay limitaciones:\n",
    "\n",
    "1. **Selection bias:** Elegimos SPY y el periodo de análisis después de ver los datos\n",
    "2. **Parámetros:** K=4, ventanas, definición de regímenes favorables\n",
    "3. **Costos ignorados:** Transacciones, slippage, impuestos\n",
    "\n",
    "Para uso real, se recomienda:\n",
    "- Paper trading antes de capital real\n",
    "- Análisis de sensibilidad a parámetros\n",
    "- Simulación de costos realistas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Generación de Series Sintéticas\n",
    "\n",
    "Usamos la matriz de transición para simular secuencias de regímenes y generar retornos sintéticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_regime_sequence(\n",
    "    trans_matrix: np.ndarray,\n",
    "    n_steps: int,\n",
    "    initial_regime: int = 0,\n",
    "    random_state: int = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simula secuencia de regímenes usando la matriz de transición.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trans_matrix : np.ndarray\n",
    "        Matriz de transición (k x k)\n",
    "    n_steps : int\n",
    "        Número de pasos a simular\n",
    "    initial_regime : int\n",
    "        Régimen inicial\n",
    "    random_state : int\n",
    "        Semilla para reproducibilidad\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray : Secuencia de regímenes\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    k = len(trans_matrix)\n",
    "    regimes = [initial_regime]\n",
    "    \n",
    "    for _ in range(n_steps - 1):\n",
    "        current = regimes[-1]\n",
    "        probs = trans_matrix[current]\n",
    "        next_regime = np.random.choice(k, p=probs)\n",
    "        regimes.append(next_regime)\n",
    "    \n",
    "    return np.array(regimes)\n",
    "\n",
    "\n",
    "def generate_synthetic_returns(\n",
    "    regime_sequence: np.ndarray,\n",
    "    regime_params: dict,\n",
    "    random_state: int = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Genera retornos sintéticos basados en la secuencia de regímenes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    regime_sequence : np.ndarray\n",
    "        Secuencia de regímenes\n",
    "    regime_params : dict\n",
    "        {regime: {'mean': μ, 'std': σ}} parámetros por régimen\n",
    "    random_state : int\n",
    "        Semilla para reproducibilidad\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray : Retornos sintéticos\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    returns = []\n",
    "    for regime in regime_sequence:\n",
    "        params = regime_params[regime]\n",
    "        r = np.random.normal(params['mean'], params['std'])\n",
    "        returns.append(r)\n",
    "    \n",
    "    return np.array(returns)\n",
    "\n",
    "# TODO: Estimar parámetros por régimen de los datos reales\n",
    "# regime_params = {}\n",
    "# for regime in range(K_REGIMES):\n",
    "#     regime_returns = df_train.loc[labels == regime, 'returns']\n",
    "#     regime_params[regime] = {\n",
    "#         'mean': regime_returns.mean(),\n",
    "#         'std': regime_returns.std()\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generar múltiples series sintéticas\n",
    "# n_simulations = 100\n",
    "# n_steps = len(df_train)\n",
    "# \n",
    "# synthetic_series = []\n",
    "# for i in range(n_simulations):\n",
    "#     regime_seq = simulate_regime_sequence(trans_matrix, n_steps, random_state=i)\n",
    "#     returns_sim = generate_synthetic_returns(regime_seq, regime_params, random_state=i+1000)\n",
    "#     synthetic_series.append(returns_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Comparación: Series Reales vs Sintéticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_real_vs_synthetic(real_returns, synthetic_series, save_path=None):\n",
    "    \"\"\"\n",
    "    Compara propiedades estadísticas de retornos reales vs sintéticos.\n",
    "    \"\"\"\n",
    "    from statsmodels.graphics.tsaplots import acf\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # 1. Histograma de retornos\n",
    "    ax = axes[0, 0]\n",
    "    ax.hist(real_returns, bins=50, density=True, alpha=0.7, label='Real', color='blue')\n",
    "    for i, syn in enumerate(synthetic_series[:5]):\n",
    "        ax.hist(syn, bins=50, density=True, alpha=0.2, color='red')\n",
    "    ax.hist(synthetic_series[0], bins=50, density=True, alpha=0.5, label='Sintético', color='red')\n",
    "    ax.set_title('Distribución de Retornos')\n",
    "    ax.legend()\n",
    "    ax.set_xlim(-0.1, 0.1)\n",
    "    \n",
    "    # 2. ACF de retornos\n",
    "    ax = axes[0, 1]\n",
    "    acf_real = acf(real_returns.dropna(), nlags=30)\n",
    "    ax.bar(range(len(acf_real)), acf_real, alpha=0.7, label='Real', color='blue', width=0.4)\n",
    "    acf_syn = np.mean([acf(s, nlags=30) for s in synthetic_series], axis=0)\n",
    "    ax.bar(np.arange(len(acf_syn)) + 0.4, acf_syn, alpha=0.7, label='Sintético (media)', color='red', width=0.4)\n",
    "    ax.set_title('ACF de Retornos')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Lag')\n",
    "    \n",
    "    # 3. ACF de |retornos|\n",
    "    ax = axes[1, 0]\n",
    "    acf_real_abs = acf(np.abs(real_returns.dropna()), nlags=30)\n",
    "    ax.bar(range(len(acf_real_abs)), acf_real_abs, alpha=0.7, label='Real', color='blue', width=0.4)\n",
    "    acf_syn_abs = np.mean([acf(np.abs(s), nlags=30) for s in synthetic_series], axis=0)\n",
    "    ax.bar(np.arange(len(acf_syn_abs)) + 0.4, acf_syn_abs, alpha=0.7, label='Sintético (media)', color='red', width=0.4)\n",
    "    ax.set_title('ACF de |Retornos| (Volatility Clustering)')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Lag')\n",
    "    \n",
    "    # 4. Tabla de momentos\n",
    "    ax = axes[1, 1]\n",
    "    ax.axis('off')\n",
    "    \n",
    "    moments_real = [\n",
    "        real_returns.mean(), real_returns.std(), \n",
    "        real_returns.skew(), real_returns.kurtosis()\n",
    "    ]\n",
    "    moments_syn = [\n",
    "        np.mean([s.mean() for s in synthetic_series]),\n",
    "        np.mean([s.std() for s in synthetic_series]),\n",
    "        np.mean([pd.Series(s).skew() for s in synthetic_series]),\n",
    "        np.mean([pd.Series(s).kurtosis() for s in synthetic_series]),\n",
    "    ]\n",
    "    \n",
    "    table_data = [\n",
    "        ['', 'Real', 'Sintético'],\n",
    "        ['Media', f'{moments_real[0]:.6f}', f'{moments_syn[0]:.6f}'],\n",
    "        ['Std', f'{moments_real[1]:.6f}', f'{moments_syn[1]:.6f}'],\n",
    "        ['Skewness', f'{moments_real[2]:.4f}', f'{moments_syn[2]:.4f}'],\n",
    "        ['Kurtosis', f'{moments_real[3]:.4f}', f'{moments_syn[3]:.4f}'],\n",
    "    ]\n",
    "    \n",
    "    table = ax.table(cellText=table_data, loc='center', cellLoc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.2, 1.8)\n",
    "    ax.set_title('Comparación de Momentos')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        save_figure(fig, save_path)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# TODO: Ejecutar comparación\n",
    "# save_path = f\"{FIGURES_PATH}real_vs_sintetico.png\" if SAVE_FIGURES else None\n",
    "# compare_real_vs_synthetic(df_train['returns'], synthetic_series, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación\n",
    "\n",
    "TODO: Discutir qué propiedades captura el modelo y cuáles no:\n",
    "- ¿Las series sintéticas tienen volatility clustering?\n",
    "- ¿Capturan el exceso de kurtosis?\n",
    "- Limitaciones del enfoque de regímenes i.i.d. dentro de cada régimen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Conclusiones y Extensiones Futuras\n",
    "\n",
    "### Resumen de resultados\n",
    "\n",
    "TODO: Completar con resultados reales:\n",
    "- Performance de la estrategia vs buy & hold\n",
    "- ¿El modelo añade valor después de costos?\n",
    "- Robustez de los resultados\n",
    "\n",
    "### Extensiones posibles\n",
    "\n",
    "1. **Jump Models / Hidden Semi-Markov Models**\n",
    "   - Modelan explícitamente la duración de los regímenes\n",
    "   - Resuelven la limitación de \"sin memoria de duración\"\n",
    "\n",
    "2. **Predicción de régimen con ML**\n",
    "   - Usar features adicionales (VIX, spreads de crédito, etc.)\n",
    "   - Random Forest / XGBoost para predecir el régimen del siguiente día\n",
    "\n",
    "3. **Ensemble de modelos**\n",
    "   - Combinar K-Means con otros indicadores\n",
    "   - Reducir dependencia de un solo modelo\n",
    "\n",
    "4. **Optimización de la estrategia**\n",
    "   - Posiciones parciales según confianza del régimen\n",
    "   - Reglas de confirmación (esperar N días en nuevo régimen)\n",
    "\n",
    "**Próximos pasos del TFM:** Implementar jump models y comparar con el enfoque actual."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
